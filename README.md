# RoRD  
Rotation Robust Descriptors  

## Abstract   
We present a novel framework that combines learning of invariant descriptors through data augmentation and orthographic viewpoint projection. We propose *rotation-robust* local descriptors, learnt through training data augmentation based on rotation homographies, and a *correspondence ensemble* technique that combines vanilla feature correspondences with those obtained through rotation-robust features. Using a range of benchmark datasets as well as contributing a new bespoke dataset for this research domain, we evaluate the effectiveness of the proposed approach on key tasks including pose estimation and visual place recognition.  

## Code  
Coming Soon  

## Dataset  
Coming Soon  

## Results  
Coming Soon  